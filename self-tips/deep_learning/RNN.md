# RNN

RNN方程
$$
a^{(t)} = b + Wh^{(t-1)} + Ux^{(t)} \\
h^{(t)} = tanh(a^{(t)}) \\
o^{(t)} = c + Vh^{(t)} \\
\hat{y}^{(t)} = softmax(o^{(t)})
$$
其中参数偏置向量$b$和$c$连同权重矩阵$U$、$V$、$W$，分别对应于输入到隐藏、隐藏到输出和隐藏到隐藏的隐藏的连接。这个循环网络将一个输入序列映射到相同长度的输出序列。与$x$序列配对的$y$的总损失就是所有时间步的损失之和。例如$L^{(t)}$为给定的$x^{(1)},\dots, x^{(t)}$后$y^{(t)}$的负对数似然，则
$$
L(\{x^{(1)},\dots, x^{(t)}\},\{y^{(1)},\dots,y^{(\tau)}\}) \\
=\sum_t(L^{(t)}) \\
=-\sum_tlogp_{model}(y^{(t)} | x^{(1)},\dots,x^{(t)})
$$


